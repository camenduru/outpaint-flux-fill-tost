{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!pip install torchsde einops diffusers transformers accelerate peft timm kornia aiohttp\n",
    "!apt install -qqy\n",
    "\n",
    "!git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI\n",
    "!git clone https://github.com/ltdrdata/ComfyUI-Manager /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-fill-dev.safetensors -d /content/ComfyUI/models/unet -o flux1-fill-dev.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/ComfyUI/models/clip -o clip_l.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp16.safetensors -d /content/ComfyUI/models/clip -o t5xxl_fp16.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/ComfyUI/models/vae -o ae.sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/ComfyUI\n",
    "\n",
    "import os, shutil, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from nodes import NODE_CLASS_MAPPINGS\n",
    "from comfy_extras import  nodes_flux, nodes_differential_diffusion\n",
    "\n",
    "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
    "DifferentialDiffusion = nodes_differential_diffusion.NODE_CLASS_MAPPINGS[\"DifferentialDiffusion\"]()\n",
    "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
    "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
    "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
    "\n",
    "ImagePadForOutpaint =  NODE_CLASS_MAPPINGS[\"ImagePadForOutpaint\"]()\n",
    "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
    "FluxGuidance = nodes_flux.NODE_CLASS_MAPPINGS[\"FluxGuidance\"]()\n",
    "InpaintModelConditioning = NODE_CLASS_MAPPINGS[\"InpaintModelConditioning\"]()\n",
    "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    unet = UNETLoader.load_unet(\"flux1-fill-dev.safetensors\", \"default\")[0]\n",
    "    unet = DifferentialDiffusion.apply(unet)[0]\n",
    "    clip = DualCLIPLoader.load_clip(\"google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n",
    "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    input_image = values['input_image']\n",
    "    input_image = download_file(url=input_image, save_dir='/content/ComfyUI/input', file_name='input_image')\n",
    "    left = values['left']\n",
    "    right = values['right']\n",
    "    top = values['top']\n",
    "    bottom = values['bottom']\n",
    "    feathering = values['feathering']\n",
    "    positive_prompt = values['positive_prompt']\n",
    "    negative_prompt = values['negative_prompt']\n",
    "    seed = values['seed']\n",
    "    steps = values['steps']\n",
    "    guidance = values['guidance']\n",
    "    cfg = values['cfg']\n",
    "    sampler_name = values['sampler_name']\n",
    "    scheduler = values['scheduler']\n",
    "\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "    print(seed)\n",
    "\n",
    "    conditioning_positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
    "    conditioning_negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
    "    image = LoadImage.load_image(input_image)[0]\n",
    "    pixels, mask = ImagePadForOutpaint.expand_image(image, left, top, right, bottom, feathering=feathering)\n",
    "    conditioning_positive = FluxGuidance.append(conditioning_positive, guidance)[0]\n",
    "    positive, negative, latent_image = InpaintModelConditioning.encode(conditioning_positive, conditioning_negative, pixels, vae, mask, noise_mask=False)\n",
    "    samples = KSampler.sample(unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0)[0]\n",
    "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
    "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(f\"/content/outpaint-flux-fill-{seed}-tost.png\")\n",
    "\n",
    "    result = f\"/content/outpaint-flux-fill-{seed}-tost.png\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "        \"input\": {\n",
    "        \"input_image\": \"https://files.catbox.moe/pqi6yz.png\",\n",
    "        \"left\": 600,\n",
    "        \"right\": 600,\n",
    "        \"top\": 0,\n",
    "        \"bottom\": 0,\n",
    "        \"feathering\": 24,\n",
    "        \"positive_prompt\": \"\",\n",
    "        \"negative_prompt\": \"\",\n",
    "        \"seed\": 0,\n",
    "        \"steps\": 20,\n",
    "        \"guidance\": 30,\n",
    "        \"cfg\": 1.0,\n",
    "        \"sampler_name\": \"euler\",\n",
    "        \"scheduler\": \"normal\"\n",
    "    }\n",
    "}\n",
    "image = generate(input)\n",
    "Image.open(image)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
